{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Home Assignment 1\n",
    "## Data Science IV, Summer Semester 2021\n",
    "### Instructor: Johannes Wachs\n",
    "----\n",
    "### Instructions \n",
    "Answer the following questions with a mixture of code (Python 3) and markdown cells, as appropriate. Your submission should be a Jupyter notebook (.ipynb). Your notebook should run from beginning to end - please test this before you submit. You may use libraries or code written in class, unless specifically noted otherwise.\n",
    "\n",
    "Submit your solutions via Learn by ***23.59pm on Wednesday, March 31st 2021***. Late submissions are accepted for 12 hours following the deadline, with 1/3 of the total possible points deducted from the score.\n",
    "\n",
    "It is ok to borrow code from online sources, if you cite all your sources. Plagiarism will result in an automatic score of 0 points. You may discuss the assignment with your classmates, but everyone should write their own code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please fill in:\n",
    "Student name: me\n",
    "\n",
    "WU Student ID: me "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Task 1: Write your own bootstrap. (20 Points)\n",
    "Write a function that:\n",
    "- takes a list of numbers as input\n",
    "- calculates their mean\n",
    "- bootstraps (1000 times) the mean\n",
    "- returns a list with three elements: the mean, and the lower and upper bounds of the 95\\% confidence interval of the bootstrapped mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(16)\n",
    "\n",
    "def bootstrap_mean_CI(input_list):\n",
    "    # bootstraping\n",
    "    bootstraped_mean = [np.mean(np.random.choice(a=input_list,\n",
    "                                                 replace=True,\n",
    "                                                 size=len(input_list))) for _ in range(1000)]\n",
    "    # confidence interval\n",
    "    ci_low = np.percentile(bootstraped_mean, 2.5)\n",
    "    ci_up = np.percentile(bootstraped_mean, 97.5)\n",
    "    \n",
    "    return [np.mean(input_list), ci_low, ci_up]\n",
    "\n",
    "# tests\n",
    "# l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# print(bootstrap_mean_CI(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a more general function that takes two inputs:\n",
    "- a list of numbers\n",
    "- a function implementing a statistical measure (i.e. the mean, median, variance)\n",
    "And outputs the statistic and a bootstrapped estimate of the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "def bootstrap_general_CI(input_list, statistical_function):\n",
    "    # bootstraping\n",
    "    bootstraped = [statistical_function(np.random.choice(a=input_list,\n",
    "                                                 replace=True, \n",
    "                                                 size=len(input_list))) for _ in range(1000)]\n",
    "    # confidence interval\n",
    "    ci_low = np.percentile(bootstraped, 2.5)\n",
    "    ci_up = np.percentile(bootstraped, 97.5)\n",
    "\n",
    "    return [statistical_function(input_list), ci_low, ci_up]\n",
    "\n",
    "\n",
    "# tests\n",
    "# print(bootstrap_general_CI(l, np.mean))\n",
    "# print(bootstrap_general_CI(l, np.median))\n",
    "# print(bootstrap_general_CI(l, np.var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1000 samples from a Poisson distribution with mean 10. Apply your general function to calculate the mean and estimate the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.889, 9.69, 10.081]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.random.poisson(lam=10.0, size=1000)\n",
    "bootstrap_general_CI(samples, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Task 2: Finding correlations in random data. (20 Points)\n",
    "- Generate 100 vectors of 100 numbers each, drawn from a normal distribution with mean 0 and standard deviation 1.\n",
    "- Calculate the Pearson correlations between all pairs of vectors.\n",
    "- Plot a histogram of the correlations - be sure to label your axes.\n",
    "- Select the pair of vectors with the greatest (in absolute value) correlation. Calculate the statistical significance of this correlation, either using a built in library function, or by writing your own.\n",
    "- Interpret your findings: is the correlation statistically significant? Hint: think of jellybeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. absolute correlation between two pairs of vectors is: 0.37598473642109953\n",
      "P-value of max absolute correlation is: 0.00011571789441034446 and is statistically significant, since p<0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 100 random vectors drawn from a normal dist with mean of 0 and std of 1\n",
    "np.random.seed(16)\n",
    "vectors = [np.random.normal(loc=0, scale=1, size=100) for _ in range(100)]\n",
    "\n",
    "# all possible pairs of vectors\n",
    "vector_pairs = list(combinations(vectors, 2))\n",
    "\n",
    "# dictionary containing pearson correlation and p-value between all vector pairs\n",
    "pearson = dict([pearsonr(pair[0], pair[1]) for pair in vector_pairs])\n",
    "\n",
    "# plot data\n",
    "pearson_coef = pearson.keys()\n",
    "\n",
    "sns.histplot(pearson_coef,\n",
    "         bins=20,\n",
    "         color='blue')\n",
    "\n",
    "plt.ylabel('Frequency', size=15)\n",
    "plt.xlabel('Pearson Correlation Coefficient', size=15)\n",
    "\n",
    "# since scipy.stats.pearsonr returns p-value I will just use that\n",
    "max_abs = max(pearson_coef, key=abs)\n",
    "p_value_of_max = pearson[max_abs]\n",
    "\n",
    "print('Max. absolute correlation between two pairs of vectors is:', abs(max_abs))\n",
    "print('P-value of max absolute correlation is:', p_value_of_max, 'and is statistically significant, since p<0.05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Task 3: Regex practice (20 Points)\n",
    "- Using the library re, write a function including a regex that finds the positions of all leading 0s. Example: \"I have 023 apples and 0301 oranges and 008 strawberries\" has four leading zeros.\n",
    "- Define a function that finds all dates in a string of the format dd-mm-yyyy OR mm-dd-yyyy. To keep it simple invalid dates (for example 50-50-2004) are ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def leading_zeros(input_string):\n",
    "    regex = re.compile(r'\\b(0+)')\n",
    "    matches = regex.finditer(input_string)\n",
    "    # I am not quite sure if we should return start, span or end of position so I will stick with start\n",
    "    return [m.start() for m in matches]\n",
    "\n",
    "# tests\n",
    "# test_str = 'I have 023 apples and 0301 oranges and 008123 strawberries'\n",
    "# print(leading_zeros(test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_dates(input_string):\n",
    "    regex = re.compile(r'\\b\\d{2}-\\d{2}-\\d{4}\\b')\n",
    "    result = regex.findall(input_string)\n",
    "    return result\n",
    "\n",
    "# tests\n",
    "# test_str = \"\"\"Okay this is some random text written on 20-03-2021 22-03-2229\n",
    "#             and it should work when I execute it at 31.03.2021 (this one is invalid due to dots)\n",
    "#             and this one as well 23.2020.15 and this one is valid 20.20.2021 but this one is not 002-23-2921\n",
    "#             this one not as well 20-2220-211123 and I will submit this on 31-03-2021 at midnight and this one is invalid\n",
    "#             203-203-2021, 2020-21-12\"\"\"\n",
    "# print(find_all_dates(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Task 4: Python or Java? (40 Points)\n",
    "Stack Overflow is a platform for people to ask and answer questions about computer programming. The site uses a system of tags to label posts. These tags help users search for questions. Often users do not tag their posts but NLP can help. \n",
    "\n",
    "In this task, your goal will be to train a machine learning classifier to distinguish between questions tagged *python* and *java* using the text of the question. The resulting classifier represents a first step towards a system that can automatically categorize new incoming posts.\n",
    "\n",
    "I have provided you with a random sample of 1000 posts tagged python and 1000 posts tagged java. Note that none of the posts in your sample have been tagged with both python and java. To make the task more challenging, I have removed the substrings python, java, and py from the questions.\n",
    "\n",
    "This task will require several steps. Feel free to adapt code from the in-class demonstration.\n",
    "\n",
    "Steps:\n",
    "- Read in the file python_or_java.csv\n",
    "- Process the text as discussed during the class.\n",
    "- Create a document-term matrix, weighted via TD-IDF.\n",
    "- Carry out a test-train split or cross-validation procedure\n",
    "- Train a classifier to distinguish Python from Java posts on training data.\n",
    "- Evaluate the performance of your classifier on held out data. You should report at least two evaluation statistics. What is the baseline accuracy of a classifier that always guesses Python?\n",
    "- What text features are most suggestive of a Python post? A Java post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer() \n",
    "en_stopwords= stopwords.words('english')\n",
    "\n",
    "# I took this part of code from your notebook, since it is written that we should process data as discussed in class,\n",
    "# and I also understand clearly what is happening here\n",
    "def get_wordnet_pos(token):\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, #map\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def processing_pipeline(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    stemmed_tokens =[ps.stem(token) for token in lemmatized_tokens]\n",
    "    processed_tokens = [token for token in stemmed_tokens if token not in en_stopwords]\n",
    "    processed_tokens = [token for token in processed_tokens if token not in string.punctuation]\n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better visibility of post-text and token columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# load csv and process post text column\n",
    "# since its written that we only need to hand in jupyternotebook I suppose you will have csv file named as it was given to us\n",
    "df = pd.read_csv('python_or_java.csv')\n",
    "df['processed_text'] = df['Body'].apply(lambda text: processing_pipeline(text))\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.498\n",
      "========================================\n",
      "Random Forest Model Accuracy: 0.908\n",
      "========================================\n",
      "Confusion Matrix: [[181  20]\n",
      " [ 17 182]]\n",
      "========================================\n",
      "Accuracy (10-fold): 0.92125\n",
      "========================================\n",
      "AUC Score: 0.972\n",
      "========================================\n",
      "public\n",
      "def\n",
      "python\n",
      "java\n",
      "print\n",
      "void\n",
      "new\n",
      "import\n",
      "string\n",
      "self\n"
     ]
    }
   ],
   "source": [
    "# I will perform classification task with the help of random forests algorithm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "corpus = list([' '.join(text) for text in df['processed_text']])\n",
    "\n",
    "#keeps only the tokens that are present in at least 10 posts, and in at most 50% of posts\n",
    "vectorizer = TfidfVectorizer(min_df=10, max_df=.5) \n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "Y = np.array(df['python_post'])\n",
    "\n",
    "# random split of data into training and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "\n",
    "# Random Forest Classification task\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# baseline - always Python\n",
    "always_python_pred = np.empty(len(Y_test))\n",
    "always_python_pred.fill(1)\n",
    "print('Baseline Accuracy:', round(accuracy_score(Y_test, always_python_pred), 3))\n",
    "print(40*'=')\n",
    "\n",
    "# Radnom forest model accuracy\n",
    "print('Random Forest Model Accuracy:',round(accuracy_score(Y_test, model.predict(X_test)),3))\n",
    "print(40*'=')\n",
    "\n",
    "# Confusion Matrix:\n",
    "print('Confusion Matrix:', confusion_matrix(Y_test, model.predict(X_test)))\n",
    "print(40*'=')\n",
    "\n",
    "# 10-fold cross validation score\n",
    "accuracies = cross_val_score(estimator=model, \n",
    "                             X=X_train,\n",
    "                             y=Y_train,\n",
    "                             cv=10)\n",
    "print('Accuracy (10-fold):', np.mean(accuracies))\n",
    "print(40*'=')\n",
    "\n",
    "# Area Under the Curve score\n",
    "print('AUC Score:', round(roc_auc_score(Y_test,Y_pred),3))\n",
    "print(40*'=')\n",
    "\n",
    "\n",
    "f_importances = pd.Series(model.feature_importances_).sort_values(ascending=False)[:10]\n",
    "\n",
    "# Feature importances\n",
    "for i in f_importances.index:\n",
    "    print(vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried a lot to come up with a solution on how to get feature importance for both classes separatly but so far I had no success. I would really appreciate your feedback on this matter. Thank you in advance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
